{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "eeaae9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheenadyNN(): \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from tensorflow.python.keras.models import Sequential\n",
    "    from tensorflow.python.keras.layers import Dense\n",
    "    from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "    from keras import layers\n",
    "    #load pickled dataframe\n",
    "    intrinsicdf=pd.read_pickle('C:\\\\Users\\\\johns\\\\OneDrive\\\\Desktop\\\\Python Project\\\\intrinsic_hardness1.pkl')\n",
    "    intrinsicdf = intrinsicdf.dropna(axis=0)\n",
    "    target=intrinsicdf[\"intrinsic_hardness\"]\n",
    "    featuresdicseries=intrinsicdf[\"brgoch_feats\"]\n",
    "    featuresdiclist=list(featuresdicseries)\n",
    "    features = pd.DataFrame.from_records(featuresdiclist)\n",
    "    features = features.dropna(axis=0)\n",
    "    features[\"targetdata\"]=intrinsicdf[\"intrinsic_hardness\"]\n",
    "    dataset=features.values\n",
    "    mask = ~np.isnan(dataset).any(axis=1)\n",
    "    # Use the mask to index the array and remove the rows with NaN values\n",
    "    newdataset = dataset[mask]\n",
    "    x = newdataset[:,0:150]\n",
    "    y = newdataset[:,150]\n",
    "    y=np.reshape(y, (-1,1))\n",
    "    \n",
    "    #create the architecture of the neural network\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import optimizers\n",
    "    from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "    adam_opt = Adam(learning_rate=0.0001)\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_x.fit(x)\n",
    "    xscale=scaler_x.transform(x)\n",
    "    scaler_y.fit(y)\n",
    "    yscale=scaler_y.transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, input_dim=150, kernel_initializer='normal', activation='relu'))\n",
    "    #add dropout layer to prevent overfitting of data \n",
    "    model.add(layers.Dropout(0.25))\n",
    "    #model.add(Dense(13, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=adam_opt, metrics=['mse','mae'])\n",
    "    #train the neural network \n",
    "    history = model.fit(X_train, y_train, epochs=300, batch_size=100,  verbose=1, validation_split=0.2)\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    #creates a graph showing the model vs testing loss, uncomment to visualize \n",
    "    \"\"\"plt.plot(history.history['loss'],color=\"blue\")\n",
    "    plt.plot(history.history['val_loss'],color=\"red\")\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
